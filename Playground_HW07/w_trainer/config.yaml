### environment ###
model_name: "luhua/chinese_pretrain_mrc_roberta_wwm_ext_large"
train_data_name: "data/hw7_train.json"
dev_data_name: "data/hw7_dev.json"
test_data_name: "data/hw7_test.json"
model_save_dir: "model"
seed: 0
fp16_training: True

### script ###
train: True
ensemble: True
cv_number: 3
validation: False
logging_step: 372
use_finetune_model: False

### dataset split ###
use_dev_set_ratio: 0.8

### dataset parameter ###
max_question_len: 120
max_paragraph_len: 240
doc_stride: 0.50
answer_pad: 0.1  # answer appear in paragraphs[max_len*answer_pad : -max_len*answer_pad]
pick_method: 'random'
random_pick_ratio: 0.5

### hyper parameter ###
train_batch_size: 4
accum_iter: 8
num_epoch: 5
learning_rate: 0.00005
warm_up_ratio: 0.2
label_smoothing_factor: 0.1

### post process setting ###
n_best: 20
max_answer_length: 30

### save strategy ###
save_mode: 'avg_best' # avg_best , avg_last , best
avg_number: 5
save_baseline: 0.75
